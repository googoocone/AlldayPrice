"""
ì˜¬í”„ í¬ë¡¤ëŸ¬ - ë©”ì¸ ì‹¤í–‰ íŒŒì¼
í•˜ë£¨ 1íšŒ ì‹¤í–‰í•˜ì—¬ ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ ë° ì¿ í° ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""
import os
import sys
import asyncio
import argparse
from datetime import datetime
from typing import Dict

from config import CATEGORIES, LOGS_PATH
from auth import AuthManager
from database import Database
from scraper import ProductScraper, CouponScraper


def setup_logging():
    """ë¡œê·¸ í´ë” ì„¤ì •"""
    os.makedirs(LOGS_PATH, exist_ok=True)
    

def log_message(message: str, log_file: str = None):
    """ì½˜ì†”ê³¼ íŒŒì¼ì— ë¡œê·¸ ê¸°ë¡"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_line = f"[{timestamp}] {message}"
    print(log_line)
    
    if log_file:
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_line + "\n")


async def run_crawler(full_refresh: bool = False):
    """í¬ë¡¤ëŸ¬ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        full_refresh: Trueë©´ ëª¨ë“  ìƒí’ˆ ì •ë³´ ê°±ì‹  (ê¸°ë³¸: ê°€ê²©ë§Œ ì—…ë°ì´íŠ¸)
    """
    setup_logging()
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    today = datetime.now().strftime("%Y-%m-%d")
    log_file = os.path.join(LOGS_PATH, f"crawl_{today}.log")
    
    log_message("=" * 60, log_file)
    if full_refresh:
        log_message("ğŸš€ ì˜¬í”„(All Day Price) í¬ë¡¤ëŸ¬ ì‹œì‘ [ì „ì²´ ê°±ì‹  ëª¨ë“œ]", log_file)
    else:
        log_message("ğŸš€ ì˜¬í”„(All Day Price) í¬ë¡¤ëŸ¬ ì‹œì‘ [ê°€ê²©ë§Œ ì—…ë°ì´íŠ¸ ëª¨ë“œ]", log_file)
    log_message("=" * 60, log_file)
    
    start_time = datetime.now()
    
    # ê²°ê³¼ í†µê³„
    stats = {
        "new_products": 0,
        "updated_products": 0,
        "total_coupons": 0,
        "categories_done": 0,
        "errors": []
    }
    
    auth = AuthManager()
    db = Database()
    
    try:
        # 1. ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
        log_message("ğŸ” ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì¤‘...", log_file)
        
        # ì²« ì‹¤í–‰ì€ headless=Falseë¡œ (ìˆ˜ë™ ë¡œê·¸ì¸ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        if not await auth.ensure_logged_in(headless=False):
            log_message("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨. í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.", log_file)
            return
        
        page = await auth.get_page()
        
        # 2. ìƒí’ˆ í¬ë¡¤ë§
        log_message("\nğŸ“¦ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘...", log_file)
        
        product_scraper = ProductScraper(page, db, full_refresh=full_refresh)
        sample_products_by_brand: Dict[str, str] = {}  # ë¸Œëœë“œë³„ ìƒ˜í”Œ ìƒí’ˆ ID
        
        for category_name, category_code in CATEGORIES.items():
            try:
                log_message(f"\nğŸ“‚ [{category_name}] ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§...", log_file)
                
                products = await product_scraper.scrape_ranking_page(category_name, category_code)
                save_stats = await product_scraper.save_products_to_db(products)
                
                stats["new_products"] += save_stats["new_count"]
                stats["updated_products"] += save_stats["updated_count"]
                stats["categories_done"] += 1
                
                # ë¸Œëœë“œë³„ ìƒ˜í”Œ ìƒí’ˆ ì €ì¥ (ì¿ í° í¬ë¡¤ë§ìš©)
                for product in products:
                    brand = product["brand"]
                    if brand not in sample_products_by_brand:
                        sample_products_by_brand[brand] = product["oliveyoung_id"]
                
                total_saved = save_stats["new_count"] + save_stats["updated_count"]
                log_message(f"  âœ… [{category_name}] {total_saved}ê°œ ì €ì¥ (ì‹ ê·œ: {save_stats['new_count']}, ì—…ë°ì´íŠ¸: {save_stats['updated_count']})", log_file)
                
            except Exception as e:
                error_msg = f"[{category_name}] í¬ë¡¤ë§ ì˜¤ë¥˜: {e}"
                stats["errors"].append(error_msg)
                log_message(f"  âŒ {error_msg}", log_file)
        
        # 3. ì¿ í° í¬ë¡¤ë§
        log_message("\nğŸ« ì¿ í° í¬ë¡¤ë§ ì‹œì‘...", log_file)
        
        coupon_scraper = CouponScraper(page, db)
        coupon_count = await coupon_scraper.scrape_brand_coupons(
            product_scraper.collected_brands,
            sample_products_by_brand
        )
        stats["total_coupons"] = coupon_count
        
        # 4. ì™„ë£Œ ë¦¬í¬íŠ¸
        end_time = datetime.now()
        duration = end_time - start_time
        
        log_message("\n" + "=" * 60, log_file)
        log_message("ğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ ë¦¬í¬íŠ¸", log_file)
        log_message("=" * 60, log_file)
        log_message(f"  â±ï¸ ì†Œìš” ì‹œê°„: {duration}", log_file)
        log_message(f"  ğŸ“‚ ì™„ë£Œ ì¹´í…Œê³ ë¦¬: {stats['categories_done']}/{len(CATEGORIES)}", log_file)
        log_message(f"  ğŸ“¦ ì‹ ê·œ ìƒí’ˆ: {stats['new_products']}ê°œ", log_file)
        log_message(f"  ğŸ”„ ê°€ê²© ì—…ë°ì´íŠ¸: {stats['updated_products']}ê°œ", log_file)
        log_message(f"  ğŸ« ìˆ˜ì§‘ ì¿ í°: {stats['total_coupons']}ê°œ", log_file)
        
        if stats["errors"]:
            log_message(f"\nâš ï¸ ì˜¤ë¥˜ {len(stats['errors'])}ê±´:", log_file)
            for error in stats["errors"]:
                log_message(f"  - {error}", log_file)
        
        log_message("\nâœ… í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", log_file)
        
        # DB í†µê³„
        db_stats = db.get_stats()
        log_message(f"\nğŸ“ˆ DB í˜„í™©:", log_file)
        log_message(f"  - ì „ì²´ ìƒí’ˆ: {db_stats['total_products']}ê°œ", log_file)
        log_message(f"  - í™œì„± ì¿ í°: {db_stats['active_coupons']}ê°œ", log_file)
        
    except Exception as e:
        log_message(f"\nâŒ í¬ë¡¤ëŸ¬ ì˜¤ë¥˜ ë°œìƒ: {e}", log_file)
        raise
        
    finally:
        await auth.close()


def main():
    """í”„ë¡œê·¸ë¨ ì§„ì…ì """
    parser = argparse.ArgumentParser(description="ì˜¬í”„(All Day Price) í¬ë¡¤ëŸ¬")
    parser.add_argument(
        "--full-refresh",
        action="store_true",
        help="ì „ì²´ ê°±ì‹  ëª¨ë“œ: ëª¨ë“  ìƒí’ˆ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤ (ê¸°ë³¸: ê°€ê²©ë§Œ ì—…ë°ì´íŠ¸)"
    )
    args = parser.parse_args()
    
    asyncio.run(run_crawler(full_refresh=args.full_refresh))


if __name__ == "__main__":
    main()
